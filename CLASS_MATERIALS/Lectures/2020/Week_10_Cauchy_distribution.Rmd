---
title: "The Cauchy distribution"
author: "Peter Ralph"
date: "30 November 2020 -- Advanced Biological Statistics"
---

```{r setup, include=FALSE}
fig.dim <- 5
knitr::opts_chunk$set(fig.width=2*fig.dim,
                      fig.height=fig.dim,
                      fig.align='center')
set.seed(24)
library(matrixStats)
```



# Stochastic minute

---------------

If $X \sim \Cauchy(\text{center}=\mu, \text{scale}=\sigma)$, then $X$ has probability density
$$\begin{aligned}
    f(x \given \mu, \sigma) = \frac{1}{\pi\left( 1 + \left( \frac{x - \mu}{\sigma} \right)^2 \right)} .
\end{aligned}$$

> 1. The Cauchy is a good example of a distribution with "heavy tails":
>    rare, very large values.
>
> 2. $X$ has a Student's $t$ distribution with $\text{df}=1$.
> 
> 3. If $Z \sim \Normal(0, 1)$ and $X \sim \Normal(0,1/Z)$ then $X \sim \Cauchy(0,1)$.
>
> 4. If $X_1, X_2, \ldots, X_n$ are independent $\Cauchy(0,1)$ then
>    $\max(X_1, \ldots, X_n)$ is of size $n$.

----------------

5. If $X_1, X_2, \ldots, X_n$ are independent $\Cauchy(0,1)$ then
   $$\begin{aligned}
    \frac{1}{n} \left(X_1 + \cdots + X_n\right) \sim \Cauchy(0,1) .
   \end{aligned}$$

. . .

*Wait, what?!?*

. . .

A single value has the *same distribution* as the mean of 1,000 of them?

. . .

Let's look:
```{r cauchy_mean, fig.width=2.5*fig.dim}
meanplot <- function (rf, n=1e3, m=100) {
    x <- matrix(rf(n*m), ncol=m)
    layout(t(1:2))
    hist(x[1,][abs(x[1,])<5], breaks=20, freq=FALSE,
         main=sprintf("%d samples", m), xlab='value',
         xlim=c(-5,5))
    hist(colMeans(x)[abs(colMeans(x))<5], breaks=20, freq=FALSE,
         main=sprintf("%d means of %d each", m, n), xlab='value',
         xlim=c(-5,5))
}
```

----------

$X \sim \Normal(0,1)$
```{r normmeans}
meanplot(rnorm)
```

-----------

$X \sim \Cauchy(0,1)$
```{r cauchymeans}
meanplot(rcauchy)
```

## Another way to look at it: extreme values

```{r max_values}
n <- 100
plot(c(cummax(rcauchy(n))), type='l', ylab='max value so far', xlab='number of samples', col='red')
lines(c(cummax(rnorm(n))), col='black')
legend("bottomright", lty=1, col=c('black', 'red'), legend=c('normal', 'cauchy'))
```

## Another way to look at it: extreme values

```{r max_values2}
n <- 1000
plot(c(cummax(rcauchy(n))), type='l', ylab='max value so far', xlab='number of samples', col='red')
lines(c(cummax(rnorm(n))), col='black')
legend("bottomright", lty=1, col=c('black', 'red'), legend=c('normal', 'cauchy'))
```

## Another way to look at it: extreme values

```{r max_values3}
n <- 1e6
plot(c(cummax(rcauchy(n))), type='l', ylab='max value so far', xlab='number of samples', col='red')
lines(c(cummax(rnorm(n))), col='black')
legend("bottomright", lty=1, col=c('black', 'red'), legend=c('normal', 'cauchy'))
```

## Exercise: mixture of error rates.

Suppose you are measuring relative metabolic rates
of mice in the wild.
Because life is complicated,
the *accuracy* of your measurements varies widely.
A model of the measured rate, $R_i$,
for a mouse at temperature $T_i$ is
$$\begin{aligned}
    R_i &\sim \Normal(120 + 0.7 * (T_i - 37), 1/|E_i|) \\
    E_i &\sim \Normal(0, 1) .
\end{aligned}$$

Simulate 200 measurements from this model,
for temperatures between 36 and 38,
and try to infer the true slope (`0.7`).


## IN CLASS

```{r sim_class}
n <- 200
mice <- data.frame(
       T = runif(n, 36, 38) )
mice$E <- rnorm(n)
mice$R <- rnorm(n,
                mean=120 + 0.7 * (mice$T - 37),
                sd=1/abs(mice$E))
plot(R ~ T, data=mice, xlab='temperature', ylab='metabolic rate')
abline(120 - 0.7 * 37, 0.7, col='red')
# zoom in
plot(R ~ T, data=mice, xlab='temperature',
     ylab='metabolic rate',
     ylim=c(110, 130))
abline(120 - 0.7 * 37, 0.7, col='red')

summary(lm(R ~ T, data=mice))
```
