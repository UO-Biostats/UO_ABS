---
title: "Generalized Linear Models"
author: "Peter Ralph"
date: "1 December 2020 -- Advanced Biological Statistics"
---

```{r setup, include=FALSE}
fig.dim <- 4
knitr::opts_chunk$set(fig.width=2*fig.dim,
                      fig.height=fig.dim,
                      fig.align='center')
set.seed(23)
library(tidyverse)
library(rstan)
library(matrixStats)
options(mc.cores = parallel::detectCores())
```


# Generalized Linear Models

## Ingredients of a GLM:

1. A probability distribution, $Y$.

  > *(the "family"; describes the output)*

2. A linear predictor, $X \beta$.

  > *(connects input to output)*

3. A link function (usually, $h(\E[Y]) = X\beta$).

  > *(connects linear predictor to probability distribution)*

## Common choices:

- Linear regression:
  $$ Y \sim \Normal(X \beta, \sigma) .$$

- Logistic regression:
  $$ Y \sim \Binom(n, \logistic(X\beta)) .$$

- Gamma regression:
  $$ Y \sim \Gam(\text{scale}=\exp(X\beta)/k, \text{shape}=k) .$$

## Logistic regression, in R

```
glm(y ~ x, family=binomial)
```

. . .

```
family {stats}

Family objects provide a convenient way to specify the details of the models
used by functions such as glm.

binomial(link = "logit")
gaussian(link = "identity")
Gamma(link = "inverse")
inverse.gaussian(link = "1/mu^2")
poisson(link = "log")

Arguments

link: a specification for the model link function. This can be a
name/expression, a literal character string, a length-one character vector, or
an object of class "link-glm" (such as generated by make.link) provided it is
not specified via one of the standard names given next.

The gaussian family accepts the links (as names) identity, log and inverse; the
binomial family the links logit, probit, cauchit, (corresponding to logistic,
normal and Cauchy CDFs respectively) log and cloglog (complementary log-log);
the Gamma family the links inverse, identity and log; the poisson family the
links log, identity, and sqrt; and the inverse.gaussian family the links
1/mu^2, inverse, identity and log.
```

## 

Note that the link function is the *inverse* of what we'd write down in the model:
for instance, if the mean of the response is the exponential of the linear predictor,
i.e., if
$$
\E[Y] = \exp(X\beta) .
$$
then we have
```
link = "log"
```

. . .

Other inverses:

- `logistic` has inverse `logit`
- `identity` has inverse `identity`
- `x^2` ("squared") has inverse `sqrt`

# Unpacking logistic regression

## Simulate data

100 trials, where probability of success depends on $x$:
```{r sim_logistic, fig.width=2*fig.dim}
alpha <- -7; beta <- 1.2
x <- runif(100, 0, 10)
y <- alpha + beta * x
p <- 1 / (1 + exp(-y))
z <- rbinom(100, size=1, prob=p)
plot(z ~ x)
curve(1/(1+exp(-(-7 + 1.2 *x))), 0, 10, col='red', add=TRUE)
```

## `glm()`

```{r run_glm}
zz <- cbind(z, 1-z)
summary(glm_fit <- glm(zz ~ x, family='binomial'))
```

## Stan

::: {.columns}
:::::: {.column width=50%}

$$\begin{aligned}
    Z &\sim \Binom(1, P) \\
    P &= \logistic(\alpha + \beta X)
\end{aligned}$$

:::
:::::: {.column width=50%}


```{r stan_logistic, cache=TRUE}
logistic_block <- "
data {
    int N;
    vector[N] X;
    int<lower=0> Z[N];
}
parameters {
    real alpha;
    real beta;
}
model {
    vector[N] p;
    p = inv_logit(alpha + beta * X);
    Z ~ binomial(1, p);
}"
```

:::
::::::

## Stan: fit the model

```{r run_stan_logistic, cache=TRUE, dependson="stan_logistic"}
fit <- stan(model_code=logistic_block,
            data=list(N=100, X=x, Z=z))
rstan::summary(fit)$summary
```

## Stan: posterior distributions

```{r plot_stan_logistic, fig.width=2*fig.dim}
samples <- extract(fit)
layout(t(1:2))
hist(samples$alpha, main=expression(alpha))
abline(v=alpha, col='red'); abline(v=coef(glm_fit)[1], col='green')
hist(samples$beta, main=expression(beta))
abline(v=beta, col='red'); abline(v=coef(glm_fit)[2], col='green')
legend("topright", lty=1, col=c('red', 'green'), legend=c('truth', 'glm'))
```

# Identify the GLM

## 

::: {.columns}
:::::: {.column width=60%}

```
data {
  int N;
  vector[N] X;
  vector[N] Y;
  vector<lower=0> Z[N];
}
parameters {
  real beta[2];
}
model {
  Z ~ gamma(1, exp(- beta[1] * X - beta[2] * Y));
}
```

:::
:::::: {.column width=40%}

What is

1. the probability distribution?
  *(describes the output)*

2. the linear predictor?
  *(connects input to output)*

3. the link function?
  *(connects linear predictor to probability distribution)*


**Then,** simulate from it.

:::
::::::

## in class

```{r siminclass}
N <- 100
# Matrix of X, Y
XY <- cbind(X=rnorm(N), 
            Y=rnorm(N))
beta <- c(2, -3)
# Xbeta <- beta[1] * X + beta[2] * Y
Xbeta <- XY %*% beta
Z <- rgamma(N, shape=1, scale=exp(-Xbeta))

gZ <- glm(Z ~ XY[,"X"] + XY[,"Y"], family=Gamma(link='log'))
summary(gZ)

plot(Xbeta, Z)

```

